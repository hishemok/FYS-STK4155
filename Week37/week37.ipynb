{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exercises week 37</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercise 1: Expectation values for ordinary least squares expressions</h2>\n",
    "\n",
    "There exists a continuous function $f(\\mathbf{x})$ and a normal distributed error $\\mathbf{\\epsilon} \\sim N(0,\\sigma^2)$ which describes our data $\\mathbf{y} = f(\\mathbf{x}) + \\epsilon$. We approximate the function $f$ with our model $\\mathbf{\\tilde{y}}= \\mathbf{X\\beta}$, minimized by $(\\mathbf{y} - \\mathbf{\\tilde{y}})^2$.\n",
    "\n",
    "Show that the expectation value of $\\mathbf{y}$ for a given element in $i$:\n",
    "$$\\mathbb{E}(y_i) = \\sum_j x_{ij}\\beta_j=\\mathbf{X}_{i,*}\\mathbf{\\beta}$$ \n",
    "and its variance is:\n",
    "$$\\text{Var}(y_i) = \\sigma^2$$\n",
    "\n",
    "\n",
    "Given $\\mathbf{y} = f(\\mathbf{x}) + \\epsilon$ and $ \\epsilon \\sim N(0, \\sigma^2) $\n",
    "\n",
    "Expectation value:\n",
    "$$\\mathbb{E} (\\mathbf{y}) = \\mathbb{E}(f(\\mathbf{x}) + ϵ ) = \\mathbb{E}(f(\\mathbf{x})) $$\n",
    "Since $\\mathbb{E}(\\epsilon) = 0$, because we assume $\\epsilon$ to be normally distributed with a mean value of 0, and a variance of $\\sigma^2$.\n",
    "\n",
    "We need to keep in mind our model for $\\mathbf{y}$ is $\\mathbf{\\tilde{y}}= \\mathbf{X\\beta}$\n",
    "\n",
    "From there we can look at it element-wise:\n",
    "$$\\mathbb{E}(y_i) =  \\sum_j x_{ij} β_j  = \\mathbf{X}_{i,*}\\mathbf{\\beta}$$\n",
    "\n",
    "\n",
    "Variance:\n",
    "The variance lies in the normal distributed error $\\mathbf{\\epsilon} \\sim N(0,\\sigma^2)$. \n",
    "For each point in $\\mathbf{y}$ the variance   $\\text{Var}(y_i) =\\sigma^2$. \n",
    "And therefor $y_i ∼ N(\\mathbf{X}_{i,*}\\mathbf{\\beta},\\sigma^2)$ \n",
    "with the mean value $\\mathbf{X}_{i,*}\\mathbf{\\beta}$ and variance $\\sigma^2$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Show that $\\mathbb{E}(\\mathbf{\\hat{\\beta}}) = \\mathbf{\\beta}$ using the (OLS) expression for the optimal parameters $\\mathbf{\\hat{\\beta}}$, \n",
    "$$\\mathbf{\\hat{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y} $$\n",
    "\n",
    "Then we need the expression for $\\mathbf{y}$, $\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{\\epsilon}$ and we can substitute into the OLS expression:\n",
    "$$ \\mathbf{\\hat{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T (\\mathbf{X\\beta} + \\mathbf{\\epsilon}) $$\n",
    "$$ = (\\mathbf{X}^T \\mathbf{X})^{-1} (\\mathbf{X}^T\\mathbf{X}β + \\mathbf{X}^T\\mathbf{\\epsilon} )$$\n",
    "$$ = \\mathbf{\\beta} +  (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{\\epsilon}$$\n",
    "\n",
    "Then we can find the expectation value:\n",
    "$$\\mathbb{E}(\\mathbf{\\hat{\\beta}})   = \\mathbb{E}(\\mathbf{\\beta} +  (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{\\epsilon})$$\n",
    "$$ = \\mathbb{E} ( \\mathbf{\\beta}) + \\mathbb{E} ((\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{\\epsilon}) = \\mathbf{\\beta}$$\n",
    "This is because  $\\mathbb{E} ( \\mathbf{\\beta}) = \\mathbf{\\beta}$ and $ \\mathbb{E} ( \\epsilon) = 0$\n",
    "\n",
    "Thus, we have shown that: $ \\mathbb{E}(\\mathbf{\\hat{\\beta}}) = \\mathbf{\\beta} $\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that $\\text{Var}(\\mathbf{\\hat{\\beta}}) = \\sigma^2 (\\mathbf{X}^T \\mathbf{X})^{-1}$, we can start the same way as before:\n",
    "\n",
    "$$ \\mathbf{\\hat{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T (\\mathbf{X\\beta} + \\mathbf{\\epsilon}) $$\n",
    "$$ = (\\mathbf{X}^T \\mathbf{X})^{-1} (\\mathbf{X}^T\\mathbf{X}β + \\mathbf{X}^T\\mathbf{\\epsilon} )$$\n",
    "$$ = \\mathbf{\\beta} +  (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{\\epsilon}$$\n",
    "\n",
    "Since $\\mathbf{\\beta}$ is a constant vector, its variance is zero: $ \\text{Var}(\\mathbf{\\beta}) = 0 $\n",
    "\n",
    "Variance of linear transformation: $\\text{Var}(\\mathbf{A\\epsilon}) = \\mathbf{A}\\text{Var}(\\mathbf{\\epsilon})\\mathbf{A^T}$.\n",
    "\n",
    "Set $\\mathbf{A} = (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T$:\n",
    "$$\\text{Var}(\\mathbf{A\\epsilon}) = (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T \\text{Var}(\\epsilon) ((\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T)^T$$\n",
    "$\\text{Var}(\\epsilon) = \\sigma^2$.\n",
    "$$= (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T  ((\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T)^T \\sigma^2$$\n",
    "$$=  (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}   \\sigma^2$$\n",
    "$$ = (\\mathbf{X}^T\\mathbf{X})^{-1}\\sigma^2$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercise 2: Expectation values for Ridge regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that $\\mathbb{E}\\left[\\mathbf{\\hat{\\beta}}^{Ridge}\\right] = (\\mathbf{X}^T\\mathbf{X} + λ \\mathbf{I}_{pp})^{-1} (\\mathbf{X}^T\\mathbf{X} )\\mathbf{\\beta} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all $\\mathbf{\\hat{\\beta}}^{Ridge}  =(\\mathbf{X}^T\\mathbf{X}+  λ \\mathbf{I}_{pp})^{-1}\\mathbf{X}^T\\mathbf{y}$\n",
    "Substitute for $\\mathbf{y}$:\n",
    "$$\\mathbf{\\hat{\\beta}}^{Ridge}  =(\\mathbf{X}^T\\mathbf{X}+  λ \\mathbf{I}_{pp})^{-1}\\mathbf{X}^T (\\mathbf{X\\beta}+\\mathbf{\\epsilon})$$\n",
    "$$\\mathbf{\\hat{\\beta}}^{Ridge} = (\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1} (\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta} + \\mathbf{X}^T \\mathbf{\\epsilon}) $$\n",
    "\n",
    "Then we find the expectation value of the expression:\n",
    "$$ \\mathbb{E}\\left[\\mathbf{\\hat{\\beta}}^{Ridge}\\right] = \\mathbb{E}\\left[(\\mathbf{X}^T \\mathbf{X} + \\lambda\\mathbf{I}_{pp})^{-1} (\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta} + \\mathbf{X}^T \\mathbf{\\epsilon})\\right] $$\n",
    "$$ = (\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1} \\mathbb{E}\\left[\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta} + \\mathbf{X}^T \\mathbf{\\epsilon}\\right] $$\n",
    "And again, since $\\mathbb{E}(\\epsilon) = 0$\n",
    "$$=  \\mathbb{E}\\left[\\mathbf{\\hat{\\beta}}^{Ridge}\\right] = (\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1} \\mathbb{E}\\left[\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta}\\right]$$\n",
    "Since $\\mathbb{E}\\left[\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta}\\right]$ is a constant term:\n",
    "$$\\mathbb{E}\\left[\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta}\\right] = \\left[\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta}\\right]$$\n",
    "\n",
    "\n",
    "And therefor $$ \\mathbb{E}\\left[\\mathbf{\\hat{\\beta}}^{Ridge}\\right] = (\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1} (\\mathbf{X}^T \\mathbf{X}) \\mathbf{\\beta} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, show that the variance is:\n",
    "$$\\text{Var}\\left[\\mathbf{\\hat{\\beta}}^{Ridge} \\right] = \\sigma^2\\left[\\mathbf{X}^T\\mathbf{X} +λ \\mathbf{I} \\right]^{-1} \\mathbf{X}^T\\mathbf{X} \\left(\\left[\\mathbf{X}^T\\mathbf{X} +λ \\mathbf{I} \\right]^{-1} \\right)^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we start with the expression of $\\mathbf{\\hat{\\beta}}^{Ridge}$ and substitute for $\\mathbf{y}$:\n",
    "$$\\mathbf{\\hat{\\beta}}^{Ridge}  =(\\mathbf{X}^T\\mathbf{X}+  λ \\mathbf{I}_{pp})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "$$ = (\\mathbf{X}^T\\mathbf{X}+  λ \\mathbf{I}_{pp})^{-1}\\mathbf{X}^T (\\mathbf{X\\beta}+\\mathbf{\\epsilon})$$\n",
    "$$ = (\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1} (\\mathbf{X}^T \\mathbf{X} \\mathbf{\\beta} + \\mathbf{X}^T \\mathbf{\\epsilon})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the variance we can ignore the $\\mathbf{\\beta}$ term, because $\\text{Var}(\\mathbf{\\beta})=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Var}\\left[\\mathbf{\\hat{\\beta}}^{Ridge} \\right] = \\text{Var}\\left((\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1}  \\mathbf{X}^T \\mathbf{\\epsilon}\\right)$$\n",
    "And again we need to remember that $\\text{Var}(\\mathbf{A}\\epsilon) = \\mathbf{A}\\text{Var}(\\epsilon)\\mathbf{A}^T$ and set $\\mathbf{A}=(\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1}  \\mathbf{X}^T $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Var}\\left[\\mathbf{\\hat{\\beta}}^{Ridge} \\right] = \\left((\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1}  \\mathbf{X}^T \\right)\\text{Var}(\\mathbf{\\epsilon}) \\left((\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1}  \\mathbf{X}^T \\mathbf{\\epsilon}\\right)^T$$\n",
    "$$= \\left((\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1}  \\mathbf{X}^T \\right)\\text{Var}(\\mathbf{\\epsilon}) \\mathbf{X}((\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_{pp})^{-1})^T$$\n",
    "$$= \\sigma^2\\left[\\mathbf{X}^T\\mathbf{X} +λ \\mathbf{I} \\right]^{-1} \\mathbf{X}^T\\mathbf{X} \\left(\\left[\\mathbf{X}^T\\mathbf{X} +λ \\mathbf{I} \\right]^{-1} \\right)^T$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
